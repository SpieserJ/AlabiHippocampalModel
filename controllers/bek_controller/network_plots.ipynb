{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "from matplotlib import cm, rcParams\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set up the colormap and default settings\n",
    "cmap = cm.get_cmap('plasma')\n",
    "rcParams.update({'font.size': 12})\n",
    "\n",
    "# Load place cell and reward cell network data\n",
    "with open('pcn.pkl', 'rb') as f:\n",
    "    pc_net = pickle.load(f)\n",
    "with open('rcn.pkl', 'rb') as f:\n",
    "    rc_net = pickle.load(f)\n",
    "\n",
    "# Load environment data (place cell and reward map coordinates)\n",
    "with open('hmap_x.pkl', 'rb') as f:\n",
    "    hmap_x = pickle.load(f)\n",
    "with open('hmap_y.pkl', 'rb') as f:\n",
    "    hmap_y = pickle.load(f)\n",
    "with open('hmap_z.pkl', 'rb') as f:\n",
    "    hmap_z = np.asarray(pickle.load(f))\n",
    "with open('hmap_g.pkl', 'rb') as f:\n",
    "    hmap_g = np.asarray(pickle.load(f))\n",
    "\n",
    "goal_r = 0.3  # Define goal radius\n",
    "goalLocation = [-1, 1]  # Define goal location (can be updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probeOne(probed):\n",
    "    \"\"\"\n",
    "    Visualizes the activation of a specific place cell (probed) over the environment map.\n",
    "    \"\"\"\n",
    "    fig = plot.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    # Plot place cell activations using hexbin for better visualization\n",
    "    cntr = ax.hexbin(hmap_x, hmap_y, hmap_z[:, probed].flatten(), gridsize=50, cmap=cmap, alpha=0.6)\n",
    "\n",
    "    # Add colorbar and title\n",
    "    plot.colorbar(cntr)\n",
    "    v = f\"v_{{{probed}}}^p\"\n",
    "    plot.title(f\"Place Cell {probed} Activation\")\n",
    "    plot.show()\n",
    "\n",
    "# Calculate the total activation for each place cell\n",
    "total_activations = np.sum(hmap_z, axis=0)\n",
    "\n",
    "# Get the indices of the top 10 most activated place cells\n",
    "top_10_cells = np.argsort(total_activations)[-10:]\n",
    "\n",
    "# Plot the activations for the top 10 place cells\n",
    "for cell in top_10_cells:\n",
    "    probeOne(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_rcn_activation(context=0):\n",
    "    \"\"\"\n",
    "    Visualizes the reward cell activations across the environment.\n",
    "\n",
    "    Parameters:\n",
    "    context (int): Context index for the reward cell weights.\n",
    "    \"\"\"\n",
    "    # Load the RCN layer (reward cell network)\n",
    "    with open('rcn.pkl', 'rb') as f:\n",
    "        rc_net = pickle.load(f)\n",
    "\n",
    "    # Use the effective weights instead of w_in\n",
    "    w_in_float32 = tf.cast(rc_net.w_in_effective, tf.float32)  # Cast rc_net effective weights to float32\n",
    "\n",
    "    # Ensure that hmap_z is loaded and cast to float32\n",
    "    with open('hmap_z.pkl', 'rb') as f:\n",
    "        hmap_z = pickle.load(f)\n",
    "    hmap_z_float32 = tf.cast(hmap_z.T, tf.float32)  # Transpose and cast hmap_z to float32\n",
    "\n",
    "    # Compute the total place cell activations to use in normalizing the reward activations\n",
    "    sum_activations = tf.reduce_sum(hmap_z, axis=-1)\n",
    "    safe_denominator = tf.where(sum_activations > 0, sum_activations, 1)  # Avoid division by zero\n",
    "    safe_denominator = tf.cast(safe_denominator, tf.float32)\n",
    "\n",
    "    # Compute the reward function using the effective weights and the place cell activations\n",
    "    reward_function = tf.tensordot(w_in_float32[context], hmap_z_float32, axes=1) / safe_denominator\n",
    "\n",
    "    # Flatten reward function to ensure it's a 1D array\n",
    "    reward_function = tf.squeeze(reward_function)\n",
    "\n",
    "    # Load hmap_x and hmap_y\n",
    "    with open('hmap_x.pkl', 'rb') as f:\n",
    "        hmap_x = pickle.load(f)\n",
    "    with open('hmap_y.pkl', 'rb') as f:\n",
    "        hmap_y = pickle.load(f)\n",
    "\n",
    "    # Check if reward_function has the same shape as hmap_x and hmap_y\n",
    "    if reward_function.shape != hmap_x.shape:\n",
    "        raise ValueError(f\"Shape mismatch: reward_function has shape {reward_function.shape}, but expected {hmap_x.shape}.\")\n",
    "\n",
    "    # Plot the reward function over the environment\n",
    "    fig, ax = plt.subplots(dpi=150)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    # Create a hexbin plot for the reward activations\n",
    "    cntr = ax.hexbin(hmap_x, hmap_y, reward_function.numpy(), gridsize=100, cmap=cmap, alpha=0.6)\n",
    "\n",
    "    # Rotate the plot by 180 degrees by reversing the x and y limits\n",
    "    ax.set_ylim(5, -5)\n",
    "    ax.set_xlim(5, -5)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    # Increase the size of the map relative to the overall plot\n",
    "    fig.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05)\n",
    "\n",
    "    # Draw the goal location as a green circle\n",
    "    goal = plt.Circle(goalLocation, goal_r, color='green', alpha=0.5, fill=True)\n",
    "    ax.add_patch(goal)\n",
    "\n",
    "    # Add a colorbar for the reward values\n",
    "    fig.colorbar(cntr)\n",
    "    plt.title(f\"Reward Map Visualization for context {context}\")\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with a specific context\n",
    "plot_rcn_activation(context=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_40_values = np.sort(rc_net.w_in_effective, axis=None)[-40:]\n",
    "print(top_40_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
